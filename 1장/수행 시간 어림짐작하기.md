### 주먹구구 법칙

프로그래밍 대회나 알고리즘 문제들은 대개 수행시간과 메모리크기를 정하여 그 내에서 문제를 해결한다.

그러한 이유로 입력의 최대 크기와 알고리즘의 시간 복잡도를 보고 수행 시간을 어림짐작 할 수 있어야 한다.

CPU의 클록 속도와 1클록마다 수행할 수 있는 CPU 명령어의 수, 프로그램의 메모리 접근 패턴, 운영체제와 컴파일 버전 등

영향을 끼치는 요소가 굉장히 많지만 입력의 크기만 알고 있어도 어떤 알고리즘이 시간 안에 동작할지 대략적으로 짐작하는 것이 가능하다.

입력의 최대 크기 N이 10000이고, 테스트 케이스 하나를 푸는데 시간 제한이 1초인 문제를 풀고 있다고 가정하면

처음에 만든 알고리즘의 시간 복잡도가 O(N^3)이라고 하면 과연 이 알고리즘으로 시간 내에 문제를 풀 수 있을까?

O(N^2)이나 O(N log N)은 어떨까 이런 질문에 대답에는 주먹구구법칙은 다음과 같다.


<br>

```
입력의 크기를 시간 복잡도에 대입해서 얻은 바복문 수행 횟수에 대해 1초당 반복문수행 횟수가 1억을 넘어가면 시간 제한을

초과할 가능성이 있다.
```

<br>


이 기준을 이용해 앞의 경우 각 알고리즘을 시간 안에 실행할 수 있을지 판단해 본다.

N이 10000이라면 N^3은 1억을 훨씬 초과하고 O(N log N)은 1억에 훨씬 미치지 못한다. 

하지만 O(n^2)은 1억을 초과하지 않으므로 실행이 될 것이라 생각하기 쉽지만 직접 돌려보기전에는 뭐라고 말할 수 없다.

입력의 크기 외의 요소들이 프로그램의 수행 속도를 열배 정도는 쉽게 바꿔 놓을 수 있기 때문이다.

예를 들면 예측한 수행 횟수가 기준의 10% 이하인 경우와 기준의 10배를 넘는 경우에만 이 법칙을 사용하는 것이다.

<br>

-----------------------------------------------------------------------

### 주먹구구 법칙은 주먹구구일 뿐이다.

주먹구구 법칙은 수많은 가정 위에 지어진 사상누각이기 때문에, 절대로 맹신해서는 안된다.

이 기준보다 느리지만 시간안에 수행되는 프로그램이 얼마든지 있을 수 있고, 이 기준보다 빠르지만 시간 안에 수행 되지 않는 프로그램도 있기 때문이다.

앞의 예처럼 O(N^2) 알고리즘의 경우 다른 요소들을 참조해 시간 안에 수행될지를 판단해야하는데,

<br>

**첫째, 시간 복잡도가 프로그램의 실제 수행 속도를 반영하지 못하는 경우**
```
O 표기법으로 시간 복잡도를 표현할 때는 상수나 최고차항 이외의 항들을 모두 지워 버린다.

따라서 시간 복잡도 식에 입력의 최대 크기를 대입한 결과는 어디까지나 적당한 예측 값을 뿐 실제 프로그램이 수행하는 반복문의

수는 이 계산의 다섯배일 수도 있고, 10분의 1일 수도 있다.
```

<br>

**둘째, 반복문의 내부가 복잡한 경우**
```
반복문 내부는 단순하면 단순할 수록 좋다. 반복문의 내부가 길거나 시간이 많이 걸리는 연산 등을 많이 사용할 경우

이 가정보다 시간이 오래 걸릴수 밖에 없다.

반대로 반복문의 내부가 아주 단순한 경우에는 가정보다 프로그램이 빨리 수행된다.
```

<br>

**셋째, 메모리 사용 패턴이 복잡한 경우**
```
현대의 CPU는 메모리에 있는 자료를 직접 접근하는 대신 캐시라고 부르는 작고 빠른 메모미로 옮겨온 뒤 처리한다.

메모리에서 캐시로 자료를 가져올때는 인접한 자료들을 함께 가져오기 때문에, 인접한 자료들을 연속해서 사용하는 프로그램은

메모리에서 매번 자료를 가져올 필요 없이 캐시에 이미 저장된 자료를 사용하게 된다.

이런 차이는 시간 복잡도에는 아무런 영향을 미치지 못하지만 프로그램의 실제 수행 속도는 훨씬 빨라진다.
```

<br>

**넷째, 언어와 컴파일러 차이**
```
앞의 법칙은 최적화 옵션을 켠 현대 C++ 컴파일러를 시준으로 한다.

만약 최적화 옵션이 꺼져 있거나, 그보다 느린 언어를 사용한다면 수행 시간이 더 걸린다.
```

<br>

**다섯째, 구형 컴퓨터를 사용하는 경우**
```
당연하듯이 위의 법칙은 대략 지난 4~5년 사이에 출시된 CPU들을 기준으로 한다.

실제 알고리즘과 프로그램 구현을 참조해 속도를 어림짐작할 때는 평소에 작성하는 프로그램들의 시간 복잡도와 수행 시간의 상관 관계에 대한 

경험과 직관이 있으안 큰 도움이 된다.
```

<br>

-------------------------------------------------------------

### 실제 적용해 보기

1차원 배열에서 연속된 부분 구간 중 그합이 최대인 구간을 찾는 문제를 풀어 본다고 가정하면,

배열 {-7,4,-3,6,3,-8,3,4}에서 최대 합을 갖는 부분 구간은 {4,-3,6,3}으로 그 합은 10이다.

이 문제는 여러 가지 알고리즘으로 해결 할 수 있는 것으로 유명하다. 

시간 복잡도가 서로 다른 여러 알고리즘을 구현하고 각 알고리즘의 수행 시간이 어떻게 다른지 확인해보면,

첫째로, 모든 부분 구간을 순회하면서 그 합을 계산 하는 알고리즘을 구현한다면

```C++

const int MIN = numeric_limits<int>:: min();

int inefficienMaxSum(const vector<int> & A) {
  int N = A.size(), ret = MIN;
  for(int i = 0; i<N ;++i) {
    for(int j = i ; j < N;++j) {
      int sum = 0;
      for(int k = i;k<= j;++k){
        sum += A[k];
      }
      ret = max(ret,sum);
   }
 return ret;
}
```

와 같이 할 수 있다.

이 알고리즘은 O(N^2)개의 후보의 구간을 구간의 합을 구하는데 O(N)의 시간이 걸리기 때문에 시간 복잡도는 O(N^3)이다.

이동 평균을 빠르게 계산하기 위해 사용했던 변환을 이용해 이 알고리즘을 O(N^2) 시간에 수행하도록 개선하면 

```C++

int betterMaxSum(const vector<int> & A) {
  int N =A.size(), ret = MIN;
 
  for(int i = 0;i < N; ++i){
    int sum = 0;
    for(int j = i ; j < N ; ++j) {
    
    //  구간 A[i...j]의 합을 구하기
      sum += A[j];
      ret = max(ret sum);
    }
 }
 return ret;
}
```

처럼 개선할 수 있다. O(N)번 수행 되는 반복문이 두 개 겹쳐 있으니 O(N^2)의 시간 복잡도가 나오는 것을 알 수 있다.

분할 정복 기법을 이용하면 이보다 빠른 시간에 동작하는 알고리즘을 설계할 수 있다. 

입력받은 배열을 우선 절반으로 잘라 왼쪽 배열과 오른쪽 배열로 나눈다. 이때 우리가 원하는 최대 합 부분 구간은 두 배열 중 하나에

속해 있을 수도 있고, 두 배열 사이에 걸쳐 있을 수도 있다.

이때 각 경우의 답을 재귀 호출과 탐욕법을 이용해 계산하면 훌륭한 분할 정복 알고리즘이 된다.

```C++

int fastMaxSum(const vector<int> & A,int lo, int hi) {

// 구간이 1일 경우
  if(lo == hi) return A[lo];
  
  // 두 조각으로 나누기
  int mid = (lo + hi) /2;
  
  //두 부분에 모두 걸쳐 있는 최대 합 구간을 찾는다.
  // A[i...mid]와 A[mid + 1...j] 형태를 갖는 구간의 합으로 이루어진다.
  
  // A[i...mid] 형태를 갖는 최대 구간을 찾는다.
  int left = MIN, right = MIN, sum = 0;
  
  for(int i = mid ;i >= lo ; --i) {
    sum += A[i];
    left = max(left,sum);
  }
  
  // A[mid+1...j] 형태를 갖는 최대 구간을 찾는다.
  
  sum = 0;
  
  for(int j = mid +1; j <= hi; ++j) {
    sum += A[j];
    right = max(right, sum);
  }
  
  // 최대 구간이 두 조각 중 하나에만 속해 있는 경우의 답을 재귀 호출로 찾는다.
  int single = max(fastMaxSum(A,lo,mid),fastMaxSum(A,mid+1,hi));
  
  
  // 최대치 반환
  return max(left + right, single);

}
```

와 같이 풀면 O(N logN)의 시간 복잡도가 나온다.

마지막으로 선형 시간에 푸는 방법은 동적 계획법을 사용하는 것이다.

A[j]를 오른쪽 끝으로 갖는 구간의 최대 합을 반환하는 함수 maxAr(i)을 정의 해보면

```C++
int fastMaxSum(const vector<int> & A) {
  int N = A.size(), ret = MIN, psum = 0;
  for(int i = 0; i < N ; ++i) {
     psum = max(psum , 0) + A[i];
     ret = max(psum, ret);
  }
  return ret;
}
```

<br>

이렇게 표현이 가능한데, 이 코드는 딱 하나의 반복문으 갖고 있기 때문에, 시간 복잡도는 O(N)이 된다.

이렇게 각각 O(N^3), O(N^2) O(N logN), 그리고 O(N)의 시간 복잡도를 갖는 네 개의 알고리즘을 보았다.

이제 각 알고리즘의 수행 시간을 짐작해보면 각 테스트 케이스 별 시간 제한이 1초 이고 N의 상한이 1000, 10000,100000라고 할때,

이 중 어떤 알고리즘을 사용할 수 있을까?

<br>

**N = 1000**
```
이때 N^3은 10억으로 주먹구구 법칙의 시준을 넘어서므로 O(N^3)알고리즘을 사용할 때는 우선 주의해야한다.

하지만 반복문의 내부가 아주 단순하기 때문에 아마도 시간 안에 수행할 수 있을 것이다. 

그러하면 다른 시간복잡도의 알고리즘은 문제 없이 수행가능 할 것이다.
```

<br>

**N = 10,000**
```
이때 N^3은 기준의 1만 배인 1조이므로 O(N^3)알고리즘은 시간안에 돌아갈 가능성이 거의 없다.

반면 O(N^2)은 N^2는 1억 정도이므로 주의 할 범위 안이다. 

그러나 알고리즘의 반복문 내부도 단순하기 때문에 충분히 시간안에 돌아 갈 것이다.

그러면 이보다 따른 알고리즘들은 무리 없이 돌아 간다.
```

<br>

**N = 100,000**
```
이때는 N^2도 기준의 백배인 100억이 되기 때문에 O(N^2)도 돌아갈 가능성이 높지 않다.

반면 N logN는 대략 2천만 정도이므로 다른 두 알고리즘은 시간 안에 수월하게 돌아갈 것이다.

```

<br>

과연 짐작이 모두 맞을지 확인해보자, 실제로 입력값에 대한 시간 복잡도의 연산 횟수는 다음과 같다.

<br>

**O(N^3) 알고리즘**
```
크기 2560인 입력까지를 1초 안에 풀 수 있다고 확인 된다. 이때 2560^3은 대략 160억이다.
```

<br>

**O(N^2) 알고리즘**
```
크기 40960인 입력까지를 1초 안에 풀 수 있다고 확인 된다. 이때 40960^2은 대략 16억이다.
```

<br>

**O(N logN) 알고리즘**
```
크기가 대략 2천만인 입력까지를 1초 안에 풀 수 있다고 확인 된다. 이때 N logN은 대략 5억이다.
```

<br>

**O(N) 알고리즘**
```
크기가 대략 1억 6천만인 입력까지를 1초 안에 풀 수 있다고 확인된다.
```

<br>

다행히 세 경우 예상이 맞았음을 알 수 있다.

특히 중요한 것은 주먹구구 법칙으로 예측한 것보다 느리게 동작하는 프로그램은 없다는 점이다.

1억 이라는 기준은 가능한 한 보수적으로 정한 것이기 때문에 이 현상은 바람직한 것이다.

당연히 돌아갈 거라고 믿고 프로그램을 짰는데 너무 느린 것보다는, 시간 초과할 가능성이 있을 때 미리미리 조심하는 것이 낫기 때문이다.

1초 내에 수행할 수 있는 반복문의 수행 횟수가 알고리즘 간에 최대 100배까지 차이 나는 것도 볼 수 있다.

여기서, 우리는 굉장히 단순한 반복문 내부, 시간 복잡도 분석 과정에서 생략된 상수 등이 이런 결과를 불러왔을 거라고 짐작할 수 있다.
